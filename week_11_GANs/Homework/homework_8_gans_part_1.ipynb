{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG34LB_ov1SV"
      },
      "source": [
        "<p style=\"align: center;\"><img align=center src=\"https://drive.google.com/uc?export=view&id=1I8kDikouqpH4hf7JBiSYAeNT2IO52T-T\" width=600 height=480/></p>\n",
        "<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n",
        "\n",
        "<h3 style=\"text-align: center;\"><b>Домашнее задание. Generative adversarial networks</b></h3>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEZSpS6zv5BP"
      },
      "source": [
        "В этом домашнем задании вы обучите GAN генерировать лица людей и посмотрите на то, как можно оценивать качество генерации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIXHhd1ZvuSY"
      },
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as tt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.utils import make_grid\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set(style='darkgrid', font_scale=1.2)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets"
      ],
      "metadata": {
        "id": "8HCLdLZzmfb2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrmSpt5e478V"
      },
      "source": [
        "## Часть 1. Подготовка данных (0.5 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp2fR2Jd2eoh"
      },
      "source": [
        "В качестве обучающей выборки возьмем часть датасета [Flickr Faces](https://github.com/NVlabs/ffhq-dataset), который содержит изображения лиц людей в высоком разрешении (1024х1024). Оригинальный датасет очень большой, поэтому мы возьмем его часть. Скачать датасет можно [здесь](https://www.kaggle.com/datasets/tommykamaz/faces-dataset-small?resource=download-directory) и  [здесь](https://drive.google.com/file/d/1inyvLrN5wKBGCxQ4znMKBc64uL4uP_2x/view?usp=drive_link)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0uiO3Za40iK"
      },
      "source": [
        "Давайте загрузим наши изображения. Напишите функцию, которая строит DataLoader для изображений, при этом меняя их размер до нужного значения (размер 1024 слишком большой, поэтому мы рекомендуем взять размер 128 либо немного больше)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CObqZZVdyyVg"
      },
      "source": [
        "def get_dataloader(image_size, batch_size):\n",
        "  \"\"\"\n",
        "  Builds dataloader for training data.\n",
        "  Use tt.Compose and tt.Resize for transformations\n",
        "  :param image_size: height and wdith of the image\n",
        "  :param batch_size: batch_size of the dataloader\n",
        "  :returns: DataLoader object\n",
        "  \"\"\"\n",
        "  transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    tt.CenterCrop(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    tt.Normalize([0.5]*3, [0.5]*3)\n",
        "  ])\n",
        "\n",
        "  dataset = datasets.ImageFolder(root=\"\", transform=transform)\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "  return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwoDGf7myHPI"
      },
      "source": [
        "image_size = 128\n",
        "batch_size = 32\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "dataloader = get_dataloader(image_size, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем картинку из импортированного датасета"
      ],
      "metadata": {
        "id": "XAREMJjin2-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images, _ = next(iter(dataloader))\n",
        "images = images.to(device)\n",
        "print(images.shape)"
      ],
      "metadata": {
        "id": "GUorsWZBn645"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgJiWnue5Aim"
      },
      "source": [
        "## Часть 2. Построение и обучение модели (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n00W_EXg72er"
      },
      "source": [
        "Сконструируйте генератор и дискриминатор. Помните, что:\n",
        "* дискриминатор принимает на вход изображение (тензор размера `3 x image_size x image_size`) и выдает вероятность того, что изображение настоящее (тензор размера 1)\n",
        "\n",
        "* генератор принимает на вход тензор шумов размера `latent_size x 1 x 1` и генерирует изображение размера `3 x image_size x image_size`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLMOs5O51BdB"
      },
      "source": [
        "discriminator = nn.Sequential(\n",
        "    # in: 3 x 64 x 64\n",
        "\n",
        "    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    # out: 1 x 1 x 1\n",
        "\n",
        "    nn.Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrnjt3qZ1IBj"
      },
      "source": [
        "latent_size = 128\n",
        "\n",
        "generator = nn.Sequential(\n",
        "    # in: latent_size x 1 x 1\n",
        "\n",
        "    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh()\n",
        "    # out: 3 x 64 x 64\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDHQaIzQ0B4S"
      },
      "source": [
        "Перейдем теперь к обучению нашего GANа. Алгоритм обучения следующий:\n",
        "1. Учим дискриминатор:\n",
        "  * берем реальные изображения и присваиваем им метку 1\n",
        "  * генерируем изображения генератором и присваиваем им метку 0\n",
        "  * обучаем классификатор на два класса\n",
        "\n",
        "2. Учим генератор:\n",
        "  * генерируем изображения генератором и присваиваем им метку 0\n",
        "  * предсказываем дискриминаторором, реальное это изображение или нет\n",
        "\n",
        "\n",
        "В качестве функции потерь берем бинарную кросс-энтропию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2u0HPmk3B78"
      },
      "source": [
        "lr = 0.0001\n",
        "\n",
        "model = {\n",
        "    \"discriminator\": discriminator,\n",
        "    \"generator\": generator\n",
        "}\n",
        "\n",
        "# Функции потерь не нужны — считаем вручную:\n",
        "# Для дискриминатора:\n",
        "loss_d = -torch.mean(real_preds) + torch.mean(fake_preds)\n",
        "\n",
        "# Для генератора:\n",
        "loss_g = -torch.mean(fake_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_nMgY3w10EC"
      },
      "source": [
        "def fit(model, criterion, epochs, lr, start_idx=1):\n",
        "    model[\"discriminator\"].train()\n",
        "    model[\"generator\"].train()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Losses & scores\n",
        "    losses_g = []\n",
        "    losses_d = []\n",
        "    real_scores = []\n",
        "    fake_scores = []\n",
        "\n",
        "    # Create optimizers\n",
        "    optimizer = {\n",
        "        \"discriminator\": torch.optim.Adam(model[\"discriminator\"].parameters(),\n",
        "                                          lr=lr, betas=(0.5, 0.999)),\n",
        "        \"generator\": torch.optim.Adam(model[\"generator\"].parameters(),\n",
        "                                      lr=lr, betas=(0.5, 0.999))\n",
        "    }\n",
        "\n",
        "    n_critic = 5\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        loss_d_per_epoch = []\n",
        "        loss_g_per_epoch = []\n",
        "        real_score_per_epoch = []\n",
        "        fake_score_per_epoch = []\n",
        "        for i, (real_images, _) in enumerate(tqdm(train_dl)):\n",
        "            # Train discriminator\n",
        "            # Clear discriminator gradients\n",
        "            optimizer[\"discriminator\"].zero_grad()\n",
        "\n",
        "            # Pass real images through discriminator\n",
        "            real_preds = model[\"discriminator\"](real_images)\n",
        "            real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
        "            loss_d = -real_preds.mean() + fake_preds.mean(\n",
        "            cur_real_score = torch.mean(real_preds).item()\n",
        "\n",
        "            # Generate fake images\n",
        "            latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "            fake_images = model[\"generator\"](latent)\n",
        "\n",
        "            # Pass fake images through discriminator\n",
        "            fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n",
        "            fake_preds = model[\"discriminator\"](fake_images)\n",
        "            fake_loss = criterion[\"discriminator\"](fake_preds, fake_targets)\n",
        "            cur_fake_score = torch.mean(fake_preds).item()\n",
        "\n",
        "            real_score_per_epoch.append(cur_real_score)\n",
        "            fake_score_per_epoch.append(cur_fake_score)\n",
        "\n",
        "            # Update discriminator weights\n",
        "            loss_d = real_loss + fake_loss\n",
        "            loss_d.backward()\n",
        "            optimizer[\"discriminator\"].step()\n",
        "            loss_d_per_epoch.append(loss_d.item())\n",
        "\n",
        "            for i, (real_images, _) in enumerate(tqdm(train_dl)):\n",
        "              # Train generator\n",
        "              # Clear generator gradients\n",
        "              optimizer[\"generator\"].zero_grad()\n",
        "\n",
        "              # Generate fake images\n",
        "              latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "              fake_images = model[\"generator\"](latent)\n",
        "\n",
        "              # Try to fool the discriminator\n",
        "              preds = model[\"discriminator\"](fake_images)\n",
        "              targets = torch.ones(batch_size, 1, device=device)\n",
        "              loss_g = -preds.mean()\n",
        "\n",
        "              # Update generator weights\n",
        "              loss_g.backward()\n",
        "              optimizer[\"generator\"].step()\n",
        "              loss_g_per_epoch.append(loss_g.item())\n",
        "\n",
        "        # Record losses & scores\n",
        "        losses_g.append(np.mean(loss_g_per_epoch))\n",
        "        losses_d.append(np.mean(loss_d_per_epoch))\n",
        "        real_scores.append(np.mean(real_score_per_epoch))\n",
        "        fake_scores.append(np.mean(fake_score_per_epoch))\n",
        "\n",
        "        # Log losses & scores (last batch)\n",
        "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
        "            epoch+1, epochs,\n",
        "            losses_g[-1], losses_d[-1], real_scores[-1], fake_scores[-1]))\n",
        "\n",
        "        # Save generated images\n",
        "        if epoch == epochs - 1:\n",
        "          save_samples(epoch+start_idx, fixed_latent, show=False)\n",
        "\n",
        "    return losses_g, losses_d, real_scores, fake_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, epochs, lr, start_idx=1, lambda_gp=10):\n",
        "    model[\"discriminator\"].train()\n",
        "    model[\"generator\"].train()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    optimizer = {\n",
        "        \"discriminator\": torch.optim.Adam(model[\"discriminator\"].parameters(), lr=lr, betas=(0.5, 0.999)),\n",
        "        \"generator\": torch.optim.Adam(model[\"generator\"].parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    }\n",
        "\n",
        "    n_critic = 5\n",
        "    losses_g, losses_d, real_scores, fake_scores = [], [], [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        loss_d_per_epoch, loss_g_per_epoch = [], []\n",
        "        real_score_per_epoch, fake_score_per_epoch = [], []\n",
        "\n",
        "        for i, (real_images, _) in enumerate(tqdm(train_dl)):\n",
        "            real_images = real_images.to(device)\n",
        "\n",
        "            # ========== Обновляем дискриминатор n_critic раз ==========\n",
        "            for _ in range(n_critic):\n",
        "                optimizer[\"discriminator\"].zero_grad()\n",
        "\n",
        "                # Генерируем фейковые изображения\n",
        "                latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "                fake_images = model[\"generator\"](latent).detach()\n",
        "\n",
        "                real_preds = model[\"discriminator\"](real_images)\n",
        "                fake_preds = model[\"discriminator\"](fake_images)\n",
        "\n",
        "                # loss = -E[real] + E[fake]\n",
        "                loss_d = -real_preds.mean() + fake_preds.mean()\n",
        "\n",
        "                # [опционально] добавить gradient penalty\n",
        "                # gp = gradient_penalty(...)\n",
        "                # loss_d += lambda_gp * gp\n",
        "\n",
        "                loss_d.backward()\n",
        "                optimizer[\"discriminator\"].step()\n",
        "\n",
        "                real_score_per_epoch.append(real_preds.mean().item())\n",
        "                fake_score_per_epoch.append(fake_preds.mean().item())\n",
        "                loss_d_per_epoch.append(loss_d.item())\n",
        "\n",
        "            # ========== Обновляем генератор ==========\n",
        "            optimizer[\"generator\"].zero_grad()\n",
        "\n",
        "            latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "            fake_images = model[\"generator\"](latent)\n",
        "            preds = model[\"discriminator\"](fake_images)\n",
        "            loss_g = -preds.mean()\n",
        "\n",
        "            loss_g.backward()\n",
        "            optimizer[\"generator\"].step()\n",
        "\n",
        "            loss_g_per_epoch.append(loss_g.item())\n",
        "\n",
        "        # === Логирование ===\n",
        "        losses_g.append(np.mean(loss_g_per_epoch))\n",
        "        losses_d.append(np.mean(loss_d_per_epoch))\n",
        "        real_scores.append(np.mean(real_score_per_epoch))\n",
        "        fake_scores.append(np.mean(fake_score_per_epoch))\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], \"\n",
        "              f\"loss_g: {losses_g[-1]:.4f}, \"\n",
        "              f\"loss_d: {losses_d[-1]:.4f}, \"\n",
        "              f\"real_score: {real_scores[-1]:.4f}, \"\n",
        "              f\"fake_score: {fake_scores[-1]:.4f}\")\n",
        "\n",
        "        if epoch == epochs - 1:\n",
        "            save_samples(epoch + start_idx, fixed_latent, show=False)\n",
        "\n",
        "    return losses_g, losses_d, real_scores, fake_scores\n"
      ],
      "metadata": {
        "id": "NYIoHkdft7Fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkecCSn69DLe"
      },
      "source": [
        "Постройте графики лосса для генератора и дискриминатора. Что вы можете сказать про эти графики?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = fit(model, criterion, epochs, lr)"
      ],
      "metadata": {
        "id": "A0KnF0LcpUg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses_g, losses_d, real_scores, fake_scores = history"
      ],
      "metadata": {
        "id": "BKk4LV8Fpb-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_img = cv2.imread(f'./generated/generated-images-00{epochs}.png')\n",
        "generated_img = generated_img[:, :, [2, 1, 0]]"
      ],
      "metadata": {
        "id": "UBcXKMDKphvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.set_xticks([]); ax.set_yticks([])\n",
        "ax.imshow(generated_img)"
      ],
      "metadata": {
        "id": "meulMwY_piI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tcy59qWIpkfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(losses_d, '-')\n",
        "plt.plot(losses_g, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Discriminator', 'Generator'])\n",
        "plt.title('Losses');"
      ],
      "metadata": {
        "id": "bJW50Jz0pkoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Lm8OSGttpnzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "plt.plot(real_scores, '-')\n",
        "plt.plot(fake_scores, '-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('score')\n",
        "plt.legend(['Real', 'Fake'])\n",
        "plt.title('Scores');"
      ],
      "metadata": {
        "id": "fFI_HXrIpn7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuL3ZZvX5G29"
      },
      "source": [
        "## Часть 3. Генерация изображений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q9_WFIl-Bf6"
      },
      "source": [
        "Теперь давайте оценим качество получившихся изображений. Напишите функцию, которая выводит изображения, сгенерированные нашим генератором"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1tuaMVu1Jqx"
      },
      "source": [
        "n_images = 4\n",
        "\n",
        "fixed_latent = torch.randn(n_images, latent_size, 1, 1, device=device)\n",
        "fake_images = model[\"generator\"](fixed_latent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-ZmT6qm4ai5"
      },
      "source": [
        "def show_images(generated):\n",
        "\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHqPK3xs-Z-7"
      },
      "source": [
        "Как вам качество получившихся изображений?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0z41dA05KAa"
      },
      "source": [
        "## Часть 4. Leave-one-out-1-NN classifier accuracy (6 баллов)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C9V8DHX_ipy"
      },
      "source": [
        "### 4.1. Подсчет accuracy (1.5 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wT2uUb4_rku"
      },
      "source": [
        "Не всегда бывает удобно оценивать качество сгенерированных картинок глазами. В качестве альтернативы вам предлагается реализовать следующий подход:\n",
        "  * Сгенерировать столько же фейковых изображений, сколько есть настоящих в обучающей выборке. Присвоить фейковым метку класса 0, настоящим – 1.\n",
        "  * Построить leave-one-out оценку: обучить 1NN Classifier (`sklearn.neighbors.KNeighborsClassifier(n_neighbors=1)`) предсказывать класс на всех объектах, кроме одного, проверить качество (accuracy) на оставшемся объекте. В этом вам поможет `sklearn.model_selection.LeaveOneOut`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsrgX9X4BfE0"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Шаг 1: Подготовка моделей и трансформаций\n",
        "feature_extractor = models.resnet18(pretrained=True)\n",
        "feature_extractor = torch.nn.Sequential(*list(feature_extractor.children())[:-1])  # удаляем FC-слой\n",
        "feature_extractor.eval().to(device)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Шаг 2: Сбор фейковых и реальных изображений\n",
        "real_images = []  # тензоры реальных изображений (N, 3, H, W)\n",
        "fake_images = []  # тензоры фейковых изображений (N, 3, H, W)\n",
        "\n",
        "# Предположим, что у тебя уже есть batches:\n",
        "# real_images = next(iter(train_dl))[0][:N]  ← возьми N реальных\n",
        "# fake_images = generator(torch.randn(N, latent_size, 1, 1).to(device)).detach().cpu()\n",
        "\n",
        "# Шаг 3: Преобразование + получение признаков\n",
        "def extract_features(images_tensor):\n",
        "    features = []\n",
        "    with torch.no_grad():\n",
        "        for img in tqdm(images_tensor):\n",
        "            img = transform(img).unsqueeze(0).to(device)\n",
        "            feat = feature_extractor(img).squeeze().cpu().numpy()\n",
        "            features.append(feat)\n",
        "    return np.stack(features)\n",
        "\n",
        "# Реальные и фейковые\n",
        "X_real = extract_features(real_images)\n",
        "X_fake = extract_features(fake_images)\n",
        "\n",
        "X_all = np.vstack([X_real, X_fake])\n",
        "y_all = np.array([1]*len(X_real) + [0]*len(X_fake))\n",
        "\n",
        "# Шаг 4: Leave-One-Out + 1NN\n",
        "loo = LeaveOneOut()\n",
        "model = KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "correct = 0\n",
        "total = len(X_all)\n",
        "\n",
        "for train_index, test_index in tqdm(loo.split(X_all)):\n",
        "    X_train, X_test = X_all[train_index], X_all[test_index]\n",
        "    y_train, y_test = y_all[train_index], y_all[test_index]\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    correct += (pred == y_test)\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Leave-One-Out 1NN Accuracy: {accuracy:.4f}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRU47nCzCVnP"
      },
      "source": [
        "Что вы можете сказать о получившемся результате? Какой accuracy мы хотели бы получить и почему?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqzHnPOACgoZ"
      },
      "source": [
        "### 4.2. Визуализация распределений (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EweiItWFDYO0"
      },
      "source": [
        "Давайте посмотрим на то, насколько похожи распределения настоящих и фейковых изображений. Для этого воспользуйтесь методом, снижающим размерность (к примеру, TSNE) и изобразите на графике разным цветом точки, соответствующие реальным и сгенерированным изображенияи"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZBJWkWdCepj"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import models, transforms\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Готовим feature extractor (без FC-слоя)\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "feature_extractor = torch.nn.Sequential(*list(resnet.children())[:-1])  # (512,)\n",
        "feature_extractor.eval().to(device)\n",
        "\n",
        "# 2. Преобразования (Resize + Normalize под ImageNet)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 3. Извлекаем фичи из изображений\n",
        "def extract_features(image_batch):\n",
        "    features = []\n",
        "    with torch.no_grad():\n",
        "        for img in tqdm(image_batch):\n",
        "            x = transform(img).unsqueeze(0).to(device)\n",
        "            feat = feature_extractor(x).squeeze().cpu().numpy()\n",
        "            features.append(feat)\n",
        "    return np.stack(features)\n",
        "\n",
        "# ✅ Твои данные:\n",
        "# Пусть real_images, fake_images — это тензоры [N, 3, H, W]\n",
        "# Они уже должны быть в [0, 1] или [-1, 1], преобразуются потом\n",
        "\n",
        "X_real = extract_features(real_images)\n",
        "X_fake = extract_features(fake_images)\n",
        "\n",
        "# 4. Объединяем\n",
        "X_all = np.vstack([X_real, X_fake])\n",
        "y_all = np.array([1]*len(X_real) + [0]*len(X_fake))\n",
        "\n",
        "# 5. Применяем TSNE\n",
        "tsne = TSNE(n_components=2, perplexity=30, learning_rate=200, random_state=42)\n",
        "X_embedded = tsne.fit_transform(X_all)\n",
        "\n",
        "# 6. Рисуем\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(X_embedded[y_all==1, 0], X_embedded[y_all==1, 1], label='Real', alpha=0.6)\n",
        "plt.scatter(X_embedded[y_all==0, 0], X_embedded[y_all==0, 1], label='Fake', alpha=0.6)\n",
        "plt.title(\"t-SNE визуализация распределения признаков\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVZe9tt8DuYh"
      },
      "source": [
        "Прокомментируйте получившийся результат:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z__a1XTPEKaa"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}